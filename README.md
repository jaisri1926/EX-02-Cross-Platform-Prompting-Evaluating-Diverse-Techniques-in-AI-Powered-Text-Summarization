# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of: Comparative Analysis of Language Model Responses to Broad vs. Refined Prompts

Introduction This report evaluates how different AI language models respond to broad/unstructured prompts versus refined prompts. The comparison focuses on the quality, accuracy, and depth of responses across different scenarios.
Models Tested • GPT-4 (Advanced proprietary model) • Claude (Anthropic's AI assistant) • Gemini (Google's AI) • Llama 3 (Open-source model)
Test Scenarios and Results Scenario 1: General Knowledge Broad Prompt: "Tell me about AI." Key Findings
1.Broad Prompts vs. Refined Prompts:

oGPT-4 and Claude adapt well to both, but provide significantly deeper insights when given a structured prompt.

oGemini and Llama 3 perform better when given refined prompts, struggling with depth on broad queries.

2.Accuracy:

oAll models were generally accurate, but open-source models like Llama 3 sometimes provided less precise answers in unstructured queries.

3.Depth of Response: oGPT-4 consistently delivered the deepest responses, especially with refined prompts.

oClaude performed well in logical reasoning and creativity.

oGemini struggled slightly with depth but performed adequately.

oLlama 3 required very specific prompting for best results.

## Result
For general use cases, GPT-4 and Claude are the best choices, with GPT-4 leading in technical and deep knowledge.

•For more structured and technical explanations, Claude and Gemini can perform well if given clear instructions.

•For open-source alternatives, Llama 3 works decently but struggles without explicit prompting.

